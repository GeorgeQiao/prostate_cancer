{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_processing.py",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNLkFZ4ZFem8S+KAxSkEDrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeQiao/prostate_cancer/blob/master/feature_processing_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "UQuN-G595P8r",
        "outputId": "7b00203e-d718-41ce-afaa-53572eeb6c40"
      },
      "source": [
        "'''\n",
        "Machine Learning techniques on the features Selection - They ARE CALLABLE FUNCTIONS ONLY.\n",
        "'''\n",
        "\n",
        "# import statements\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "\n",
        "# set import variables\n",
        "pd.set_option(\"expand_frame_repr\", False)\n",
        "pd.set_option(\"max_columns\", 9)\n",
        "np.random.seed(0)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def do_t_risk(t_data, filenames, mode):\n",
        "\tif mode == 'partial':\n",
        "\t\tprint(t_data[0].head())\n",
        "\t# FEATURE SELECTION\n",
        "\t# Select K-Best Features, Scale Values and Select from RF Model\n",
        "\tkbest = SelectKBest(score_func=chi2, k=10000)\n",
        "\tscaler = StandardScaler()\n",
        "\tfs_data = []\n",
        "\tfor i, d in enumerate(t_data):\n",
        "\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\tt_rows = list(d.index)\n",
        "\t\tt_columns = d.columns[2:]\n",
        "\t\t# K-best\n",
        "        print(d)\n",
        "\t\tselector = kbest.fit(d.iloc[2:, :], d.iloc[2, :])\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data.append(pd.DataFrame(selector.transform(t_data[i].iloc[2:, :]), columns = t_columns, index=t_rows))\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Selecting k best features -\\n\", fs_data[i].head())\n",
        "\t\t# Scale \n",
        "\t\tt_columns = fs_data[i].columns\n",
        "\t\tfs_data[i] = pd.DataFrame(scaler.fit_transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Scaling data -\\n\", fs_data[i].head())\n",
        "\t\t# Select from RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=1)\n",
        "\t\tclassifier = classifier.fit(fs_data[i], d['group'])\n",
        "\t\tselector = SelectFromModel(classifier, prefit=True)\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data[i] = pd.DataFrame(selector.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tfs_data[i]['group'] = d['group']\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Selecting data from RF model -\\n\", fs_data[i].head())\n",
        "\t\tprint(\"Shape after feature selection: {}\".format(fs_data[i].shape), end=\"\\n\\n\")\n",
        "\t# RESAMPLING the data - SMOTEENN\n",
        "\tbalanced_data = [[] for _ in range(2)]\n",
        "\tfor i, d in enumerate(fs_data):\n",
        "\t\tsme = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=3))\n",
        "\t\tx, y = sme.fit_resample(fs_data[i], t_data[i]['group'])\n",
        "\t\t# x are the features and y are the targets\n",
        "\t\tbalanced_data[i].append(x)\n",
        "\t\tbalanced_data[i].append(y)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"FILENAME: {}\".format(filenames[i]), Counter(balanced_data[i][1]))\n",
        "\t# DIMENSIONALITY REDUCTION\n",
        "\t# Kernel PCA and LDA (can be toggled on or off)\n",
        "\tpca = True\n",
        "\tpca_dim = 31\n",
        "\tlda = True\n",
        "\tlda_dim = 5\n",
        "\tif pca or lda:\n",
        "\t\tdr_data = []\n",
        "\t\tfor i in range(len(filenames)):\n",
        "\t\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\t\tif pca:\n",
        "\t\t\t\tdecomposer = KernelPCA(n_components=pca_dim, kernel='rbf', gamma=0.05, degree=7)\n",
        "\t\t\t\tdr_data.append(decomposer.fit_transform(balanced_data[i][0]))\n",
        "\t\t\t\tprint(\"Shape and type after PCA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\t\t\tif lda:\n",
        "\t\t\t\tdecomposer = LinearDiscriminantAnalysis(n_components=lda_dim, solver='eigen')\n",
        "\t\t\t\tdr_data[i] = decomposer.fit_transform(dr_data[i], balanced_data[i][1])\n",
        "\t\t\t\tprint(\"Shape and type after LDA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\telse:\n",
        "\t\tdr_data.append(balanced_data[0][0])\n",
        "\t\tdr_data.append(balanced_data[1][0])\n",
        "\t# CLASSIFICATION\n",
        "\tsplits = 7\n",
        "\tseed = 7\n",
        "\tkfold = KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
        "\tresults = {'SVM': [],\n",
        "\t\t\t\t'RF': [],\n",
        "\t\t\t\t'KNN': [],\n",
        "\t\t\t\t'NB': []\n",
        "\t\t\t\t}\n",
        "\tfor i, d in enumerate(dr_data):\n",
        "\t\t# SVM\n",
        "\t\tres = []\n",
        "\t\tclassifier = SVC(gamma='auto')\n",
        "\t\tresults['SVM'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['SVM'][i] = results['SVM'][i].mean()\n",
        "\t\t# RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=7, criterion='gini')\n",
        "\t\tresults['RF'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['RF'][i] = results['RF'][i].mean()\n",
        "\t\t# KNN\n",
        "\t\tknn = KNeighborsClassifier(n_neighbors=5)\n",
        "\t\tresults['KNN'].append(cross_val_score(knn, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['KNN'][i] = results['KNN'][i].mean()\n",
        "\t\t# NB\n",
        "\t\tnb = GaussianNB()\n",
        "\t\tresults['NB'].append(cross_val_score(nb, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['NB'][i] = results['NB'][i].mean()\n",
        "\tprint(\"\\nFinal Results for datasets: {0}, {1} -\".format(filenames[0], filenames[1]))\n",
        "\tpprint(results)\n",
        "\t# PLOTTING\n",
        "\t# PCA\n",
        "\tpca = PCA(n_components = 3)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tfig = plt.figure(figsize=(10, 6))\n",
        "\tplt.suptitle(\"3-D plot for resampled data using dimesnionality reduction (group)\\n\\n\")\n",
        "\tax = fig.add_subplot(121, projection='3d')\n",
        "\tax.set_title(\"PCA\\n\\n\")\n",
        "\tax.view_init(elev=15,azim=66)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 0:\n",
        "\t\t\tt2a = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 1:\n",
        "\t\t\tt2b = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\tplt.legend((t2a, t2b),\n",
        "\t\t('0', '1'),\n",
        "\t\tscatterpoints=1,\n",
        "\t\tloc='upper right',\n",
        "\t\tncol=1,\n",
        "\t\tfontsize=10)\n",
        "\t# PCA + LDA\n",
        "\tpca = PCA(n_components = 10)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tlda = LinearDiscriminantAnalysis(n_components = 3)\n",
        "\tx_lda = lda.fit_transform(x_pca, balanced_data[0][1])\n",
        "\tax = fig.add_subplot(122, projection='3d')\n",
        "\tplt.title(\"PCA & LDA\\n\\n\")\n",
        "\tax.view_init(elev=-79,azim=-7)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 0:\n",
        "\t\t\tt2a = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 1:\n",
        "\t\t\tt2b = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\tplt.legend((t2a, t2b),\n",
        "\t\t\t\t('0', '1'),\n",
        "\t\t\t\tscatterpoints=1,\n",
        "\t\t\t\tloc='upper right',\n",
        "\t\t\t\tncol=1,\n",
        "\t\t\t\tfontsize=10)\n",
        "\t#plt.show()\n",
        "\treturn results\n",
        "\n",
        "def do_t_stage(t_data, filenames, mode):\n",
        "\tif mode == 'partial':\n",
        "\t\tprint(t_data[0].head())\n",
        "\t# FEATURE SELECTION\n",
        "\t# Select K-Best Features, Scale Values and Select from RF Model\n",
        "\tkbest = SelectKBest(score_func=chi2, k=10000)\n",
        "\tscaler = StandardScaler()\n",
        "\tfs_data = []\n",
        "\tfor i, d in enumerate(t_data):\n",
        "\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\tt_rows = list(d.index)\n",
        "\t\tt_columns = d.columns[:-3]\n",
        "\t\t# K-best\n",
        "\t\tselector = kbest.fit(d.iloc[:, :-3], d.iloc[:, -3])\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data.append(pd.DataFrame(selector.transform(t_data[i].iloc[:, :-3]), columns = t_columns, index=t_rows))\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Selecting k best features -\\n\", fs_data[i].head())\n",
        "\t\t# Scale \n",
        "\t\tt_columns = fs_data[i].columns\n",
        "\t\tfs_data[i] = pd.DataFrame(scaler.fit_transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Scaling data -\\n\", fs_data[i].head())\n",
        "\t\t# Select from RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=1)\n",
        "\t\tclassifier = classifier.fit(fs_data[i], d['TStage'])\n",
        "\t\tselector = SelectFromModel(classifier, prefit=True)\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data[i] = pd.DataFrame(selector.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tfs_data[i]['TStage'] = d['TStage']\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Selecting data from RF model -\\n\", fs_data[i].head())\n",
        "\t\tprint(\"Shape after feature selection: {}\".format(fs_data[i].shape), end=\"\\n\\n\")\n",
        "\t# RESAMPLING the data - SMOTEENN\n",
        "\tbalanced_data = [[] for _ in range(2)]\n",
        "\tfor i, d in enumerate(fs_data):\n",
        "\t\tsme = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=3))\n",
        "\t\tx, y = sme.fit_resample(fs_data[i], t_data[i]['TStage'])\n",
        "\t\t# x are the features and y are the targets\n",
        "\t\tbalanced_data[i].append(x)\n",
        "\t\tbalanced_data[i].append(y)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"FILENAME: {}\".format(filenames[i]), Counter(balanced_data[i][1]))\n",
        "\t# DIMENSIONALITY REDUCTION\n",
        "\t# Kernel PCA and LDA (can be toggled on or off)\n",
        "\tpca = True\n",
        "\tpca_dim = 31\n",
        "\tlda = True\n",
        "\tlda_dim = 5\n",
        "\tif pca or lda:\n",
        "\t\tdr_data = []\n",
        "\t\tfor i in range(len(filenames)):\n",
        "\t\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\t\tif pca:\n",
        "\t\t\t\tdecomposer = KernelPCA(n_components=pca_dim, kernel='rbf', gamma=0.05, degree=7)\n",
        "\t\t\t\tdr_data.append(decomposer.fit_transform(balanced_data[i][0]))\n",
        "\t\t\t\tprint(\"Shape and type after PCA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\t\t\tif lda:\n",
        "\t\t\t\tdecomposer = LinearDiscriminantAnalysis(n_components=lda_dim, solver='eigen')\n",
        "\t\t\t\tdr_data[i] = decomposer.fit_transform(dr_data[i], balanced_data[i][1])\n",
        "\t\t\t\tprint(\"Shape and type after LDA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\telse:\n",
        "\t\tdr_data.append(balanced_data[0][0])\n",
        "\t\tdr_data.append(balanced_data[1][0])\n",
        "\t# CLASSIFICATION\n",
        "\tsplits = 7\n",
        "\tseed = 7\n",
        "\tkfold = KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
        "\tresults = {'SVM': [],\n",
        "\t\t\t\t'RF': [],\n",
        "\t\t\t\t'KNN': [],\n",
        "\t\t\t\t'NB': []\n",
        "\t\t\t\t}\n",
        "\tfor i, d in enumerate(dr_data):\n",
        "\t\t# SVM\n",
        "\t\tres = []\n",
        "\t\tclassifier = SVC(gamma='auto')\n",
        "\t\tresults['SVM'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['SVM'][i] = results['SVM'][i].mean()\n",
        "\t\t# RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=7, criterion='gini')\n",
        "\t\tresults['RF'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['RF'][i] = results['RF'][i].mean()\n",
        "\t\t# KNN\n",
        "\t\tknn = KNeighborsClassifier(n_neighbors=5)\n",
        "\t\tresults['KNN'].append(cross_val_score(knn, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['KNN'][i] = results['KNN'][i].mean()\n",
        "\t\t# NB\n",
        "\t\tnb = GaussianNB()\n",
        "\t\tresults['NB'].append(cross_val_score(nb, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['NB'][i] = results['NB'][i].mean()\n",
        "\tprint(\"\\nFinal Results for datasets: {0}, {1} -\".format(filenames[0], filenames[1]))\n",
        "\tpprint(results)\n",
        "\t# PLOTTING\n",
        "\t# PCA\n",
        "\tpca = PCA(n_components = 3)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tfig = plt.figure(figsize=(10, 6))\n",
        "\tplt.suptitle(\"3-D plot for resampled data using dimesnionality reduction (T-Stage)\\n\\n\")\n",
        "\tax = fig.add_subplot(121, projection='3d')\n",
        "\tax.set_title(\"PCA\\n\\n\")\n",
        "\tax.view_init(elev=15,azim=66)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 0:\n",
        "\t\t\tt2a = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 1:\n",
        "\t\t\tt2b = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 2:\n",
        "\t\t\tt2c = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='b', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 3:\n",
        "\t\t\tt3a = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='r', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 4:\n",
        "\t\t\tt3b = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='m', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 5:\n",
        "\t\t\tt4 = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='c', label=balanced_data[0][1][i])\n",
        "\tplt.legend((t2a, t2b, t2c, t3a, t3b, t4),\n",
        "\t\t('T2a', 'T2b', 'T2c','T3a','T3b', 'T4'),\n",
        "\t\tscatterpoints=1,\n",
        "\t\tloc='upper right',\n",
        "\t\tncol=1,\n",
        "\t\tfontsize=10)\n",
        "\t# PCA + LDA\n",
        "\tpca = PCA(n_components = 10)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tlda = LinearDiscriminantAnalysis(n_components = 3)\n",
        "\tx_lda = lda.fit_transform(x_pca, balanced_data[0][1])\n",
        "\tax = fig.add_subplot(122, projection='3d')\n",
        "\tplt.title(\"PCA & LDA\\n\\n\")\n",
        "\tax.view_init(elev=-79,azim=-7)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 0:\n",
        "\t\t\tt2a = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 1:\n",
        "\t\t\tt2b = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 2:\n",
        "\t\t\tt2c = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='b', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 3:\n",
        "\t\t\tt3a = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='r', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 4:\n",
        "\t\t\tt3b = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='m', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 5:\n",
        "\t\t\tt4 = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='c', label=balanced_data[0][1][i])\n",
        "\tplt.legend((t2a, t2b, t2c, t3a, t3b, t4),\n",
        "\t\t\t\t('T2a', 'T2b', 'T2c','T3a','T3b', 'T4'),\n",
        "\t\t\t\tscatterpoints=1,\n",
        "\t\t\t\tloc='upper right',\n",
        "\t\t\t\tncol=1,\n",
        "\t\t\t\tfontsize=10)\n",
        "\t#plt.show()\n",
        "\treturn results\n",
        "\n",
        "\n",
        "def do_gleason(t_data, filenames, mode):\n",
        "\t# FEATURE SELECTION\n",
        "\t# Select K-Best Features, Scale, VarianceThreshold and Select From RF Model\n",
        "\tkbest = SelectKBest(score_func=chi2, k=15000)\n",
        "\tscaler = StandardScaler()\n",
        "\tthresholding = VarianceThreshold()\n",
        "\tfs_data = []\n",
        "\tfor i, d in enumerate(t_data):\n",
        "\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\tt_rows = list(d.index)\n",
        "\t\tt_columns = d.columns[:-3]\n",
        "\t\t# K-best\n",
        "\t\tselector = kbest.fit(d.iloc[:, :-3], d.iloc[:, -2])\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data.append(pd.DataFrame(selector.transform(t_data[i].iloc[:, :-3]), columns = t_columns, index=t_rows))\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Selecting k best features -\\n\", fs_data[i].head())\n",
        "\t\t# Scale \n",
        "\t\tt_columns = fs_data[i].columns\n",
        "\t\tfs_data[i] = pd.DataFrame(scaler.fit_transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Scaling data -\\n\", fs_data[i].head())\n",
        "\t\t# Variance Threshold\n",
        "\t\tfs_data[i] = pd.DataFrame(thresholding.fit_transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"After variance thresholding -\\n\", fs_data[i].head())\n",
        "\t\t# Select from RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=1)\n",
        "\t\tclassifier = classifier.fit(fs_data[i], d['Gleason'])\n",
        "\t\tselector = SelectFromModel(classifier, prefit=True)\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data[i] = pd.DataFrame(selector.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tfs_data[i]['Gleason'] = d['Gleason']\n",
        "\t\tif mode in ('show'):\n",
        "\t\t\tprint(\"Selecting data from RF model -\\n\", fs_data[i].head())\n",
        "\t\tprint(\"Shape after feature selection: {}\".format(fs_data[i].shape), end=\"\\n\\n\")\n",
        "\t# RESAMPLING data - SMOTEENN\n",
        "\tbalanced_data = [[] for _ in range(2)]\n",
        "\tfor i, d in enumerate(fs_data):\n",
        "\t\tsme = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=1))\n",
        "\t\tx, y = sme.fit_resample(fs_data[i], t_data[i]['Gleason'])\n",
        "\t\t# x are the features and y are the targets\n",
        "\t\tbalanced_data[i].append(x)\n",
        "\t\tbalanced_data[i].append(y)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"FILENAME: {}\".format(filenames[i]), Counter(balanced_data[i][1]))\n",
        "\t# DIMENSIONALITY REDUCTION\n",
        "\t# Kernel PCA and LDA (can be toggled on or off)\n",
        "\tpca = False\n",
        "\tpca_dim = 31\n",
        "\tlda = True\n",
        "\tlda_dim = 3\n",
        "\tif pca or lda:\n",
        "\t\tdr_data = []\n",
        "\t\tfor i in range(len(filenames)):\n",
        "\t\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\t\tif pca:\n",
        "\t\t\t\tdecomposer = KernelPCA(n_components=pca_dim, kernel='rbf', gamma=0.05, degree=7)\n",
        "\t\t\t\tdr_data.append(decomposer.fit_transform(balanced_data[i][0]))\n",
        "\t\t\t\tprint(\"Shape and type after PCA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\t\t\telse:\n",
        "\t\t\t\tdr_data.append(balanced_data[i][0])\n",
        "\t\t\tif lda:\n",
        "\t\t\t\tdecomposer = LinearDiscriminantAnalysis(n_components=lda_dim)\n",
        "\t\t\t\tdr_data[i] = decomposer.fit_transform(dr_data[i], balanced_data[i][1])\n",
        "\t\t\t\tprint(\"Shape and type after LDA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\telse:\n",
        "\t\tdr_data.append(balanced_data[0][0])\n",
        "\t\tdr_data.append(balanced_data[1][0])\n",
        "\t# CLASSIFICATION\n",
        "\tsplits = 10\n",
        "\tseed = 7\n",
        "\tkfold = KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
        "\tresults = {'SVM': [],\n",
        "\t\t\t\t'RF': [],\n",
        "\t\t\t\t'KNN': [],\n",
        "\t\t\t\t'NB': []\n",
        "\t\t\t\t}\n",
        "\tfor i, d in enumerate(dr_data):\n",
        "\t\t# SVM\n",
        "\t\tres = []\n",
        "\t\tclassifier = SVC(gamma='auto')\n",
        "\t\tresults['SVM'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['SVM'][i] = results['SVM'][i].mean()\n",
        "\t\t# RF\n",
        "\t\t# rf = RandomForestClassifier(n_estimators=100,n_jobs=-1,max_depth=10,max_features='auto')\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=7, max_features='auto', criterion='gini') #, n_jobs=-1\n",
        "\t\tresults['RF'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['RF'][i] = results['RF'][i].mean()\n",
        "\t\t# KNN\n",
        "\t\tk_scores = []\n",
        "\t\tfor n in range(1, 16):\n",
        "\t\t\tknn = KNeighborsClassifier(n_neighbors=3)\n",
        "\t\t\tscores = (cross_val_score(knn, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\t\tk_scores.append(scores.mean())\n",
        "\t\tresults['KNN'].append(max(k_scores))\n",
        "\t\t# NB\n",
        "\t\tnb = GaussianNB()\n",
        "\t\tresults['NB'].append(cross_val_score(nb, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['NB'][i] = results['NB'][i].mean()\n",
        "\tprint(\"\\nFinal Results for datasets: {0}, {1} -\".format(filenames[0], filenames[1]))\n",
        "\tpprint(results)\n",
        "\t# PLOTTING\n",
        "\t# PCA\n",
        "\tpca = PCA(n_components = 3)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tfig = plt.figure(figsize=(13, 7))\n",
        "\tplt.suptitle(\"3-D plot for resampled data using dimesnionality reduction (Gleason Score)\\n\\n\")\n",
        "\tax = fig.add_subplot(121, projection='3d')\n",
        "\tax.set_title(\"PCA\\n\\n\")\n",
        "\tax.view_init(elev=177,azim=-96)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 6:\n",
        "\t\t\tsix = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 7:\n",
        "\t\t\tseven = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 8:\n",
        "\t\t\teight = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='b', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 9:\n",
        "\t\t\tnine = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='r', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 10:\n",
        "\t\t\tten = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='m', label=balanced_data[0][1][i])\n",
        "\tplt.legend((six, seven, eight, nine, ten),\n",
        "\t\t('6', '7', '8','9','10'),\n",
        "\t\tscatterpoints=1,\n",
        "\t\tloc='upper right',\n",
        "\t\tncol=1,\n",
        "\t\tfontsize=10)\n",
        "\t# PCA + LDA\n",
        "\tpca = PCA(n_components = 10)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tlda = LinearDiscriminantAnalysis(n_components = 3)\n",
        "\tx_lda = lda.fit_transform(x_pca, balanced_data[0][1])\n",
        "\tax = fig.add_subplot(122, projection='3d')\n",
        "\tplt.title(\"PCA & LDA\\n\\n\")\n",
        "\tax.view_init(elev=10,azim=-112)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 6:\n",
        "\t\t\tsix = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 7:\n",
        "\t\t\tseven = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 8:\n",
        "\t\t\teight = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='b', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 9:\n",
        "\t\t\tnine = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='r', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 10:\n",
        "\t\t\tten = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='m', label=balanced_data[0][1][i])\n",
        "\tplt.legend((six, seven, eight, nine, ten),\n",
        "\t\t\t\t('6', '7', '8','9','10'),\n",
        "\t\t\t\tscatterpoints=1,\n",
        "\t\t\t\tloc='upper right',\n",
        "\t\t\t\tncol=1,\n",
        "\t\t\t\tfontsize=10)\n",
        "\t#plt.show()\n",
        "\treturn results\n",
        "\n",
        "\n",
        "def do_t_recur(t_data, filenames, mode):\n",
        "\t# FEATURE SELECTION\n",
        "\t# Scale, Use VarianceThreshold and Pearson Correlation, and Select From RF Model\n",
        "\tscaler = MinMaxScaler()\n",
        "\tthresholding = VarianceThreshold()\n",
        "\tfs_data = []\n",
        "\tfor i, d in enumerate(t_data):\n",
        "\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\tt_rows = list(d.index)\n",
        "\t\tt_columns = d.columns[:-3]\n",
        "\t\t# Replace NaN values with the column mean\n",
        "\t\tt_data[i]['Recurrence'].fillna((t_data[i]['Recurrence'].mean()), inplace=True)\n",
        "\t\t# Scale\n",
        "\t\tfs_data.append(pd.DataFrame(scaler.fit_transform(t_data[i].iloc[:, :-3]), columns=t_columns, index=t_rows))\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"Scaling data -\\n\", fs_data[i].head())\n",
        "\t\t# Variance Threshold\n",
        "\t\tselector = thresholding.fit(fs_data[i])\n",
        "\t\tt_columns = t_columns[thresholding.get_support()]\n",
        "\t\tfs_data[i] = pd.DataFrame(thresholding.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"After variance thresholding -\\n\", fs_data[i].head())\n",
        "\t\t# Select From RF\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=1)\n",
        "\t\tclassifier = classifier.fit(fs_data[i], d['Recurrence'])\n",
        "\t\tselector = SelectFromModel(classifier, prefit=True)\n",
        "\t\tt_columns = t_columns[selector.get_support()]\n",
        "\t\tfs_data[i] = pd.DataFrame(selector.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "\t\tfs_data[i]['Recurrence'] = d['Recurrence']\n",
        "\t\tif mode in ('show'):\n",
        "\t\t\tprint(\"Selecting data from RF model -\\n\", fs_data[i].head())\n",
        "\t\tprint(\"Shape after feature selection: {}\".format(fs_data[i].shape), end=\"\\n\\n\")\n",
        "\t# RESAMPLING data - SMOTEENN\n",
        "\tbalanced_data = [[] for _ in range(2)]\n",
        "\tfor i, d in enumerate(fs_data):\n",
        "\t\tsme = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=2))\n",
        "\t\tx, y = sme.fit_resample(fs_data[i], t_data[i]['Recurrence'])\n",
        "\t\t# x are the features and y are the targets\n",
        "\t\tbalanced_data[i].append(x)\n",
        "\t\tbalanced_data[i].append(y)\n",
        "\t\tprint(\"Upsampling the data... in {}\".format(filenames[i]))\n",
        "\t\tif mode == 'show':\n",
        "\t\t\tprint(\"FILENAME: {}\".format(filenames[i]), Counter(balanced_data[i][1]))\n",
        "\t# DIMENSIONALITY REDUCTION\n",
        "\t# Kernel PCA (can be toggled on or off)\n",
        "\tpca = True\n",
        "\tpca_dim = 20\n",
        "\tif pca:\n",
        "\t\tdr_data = []\n",
        "\t\tfor i in range(len(filenames)):\n",
        "\t\t\tprint(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "\t\t\tdecomposer = KernelPCA(n_components=pca_dim, kernel='rbf', gamma=0.5, degree=7)\n",
        "\t\t\tdr_data.append(decomposer.fit_transform(balanced_data[i][0]))\n",
        "\t\t\tprint(\"Shape and type after PCA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "\telse:\n",
        "\t\tdr_data.append(balanced_data[0][0])\n",
        "\t\tdr_data.append(balanced_data[1][0])\n",
        "\t# CLASSIFICATION\n",
        "\tsplits = 10\n",
        "\tseed = 7\n",
        "\tkfold = KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
        "\tresults = {'SVM': [],\n",
        "\t\t\t\t'RF': [],\n",
        "\t\t\t\t'KNN': [],\n",
        "\t\t\t\t'NB': []\n",
        "\t\t\t\t}\n",
        "\tfor i, d in enumerate(dr_data):\n",
        "\t\t# SVM\n",
        "\t\tres = []\n",
        "\t\tclassifier = SVC(gamma='auto')\n",
        "\t\tresults['SVM'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['SVM'][i] = results['SVM'][i].mean()\n",
        "\t\t# RF\n",
        "\t\t# rf = RandomForestClassifier(n_estimators=100,n_jobs=-1,max_depth=10,max_features='auto')\n",
        "\t\tclassifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=7, max_features='auto', criterion='gini', n_jobs=-1)\n",
        "\t\tresults['RF'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['RF'][i] = results['RF'][i].mean()\n",
        "\t\t# KNN\n",
        "\t\tk_scores = []\n",
        "\t\tfor n in range(1, 16):\n",
        "\t\t\tknn = KNeighborsClassifier(n_neighbors=3)\n",
        "\t\t\tscores = (cross_val_score(knn, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\t\tk_scores.append(scores.mean())\n",
        "\t\tresults['KNN'].append(max(k_scores))\n",
        "\t\t# NB\n",
        "\t\tnb = GaussianNB()\n",
        "\t\tresults['NB'].append(cross_val_score(nb, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "\t\tresults['NB'][i] = results['NB'][i].mean()\n",
        "\tprint(\"\\nFinal Results for datasets: {0}, {1} -\".format(filenames[0], filenames[1]))\n",
        "\tpprint(results)\n",
        "\t# PLOTTING\n",
        "\t# PCA\n",
        "\tpca = PCA(n_components = 3)\n",
        "\tx_pca = pca.fit_transform(balanced_data[0][0])\n",
        "\tfig = plt.figure(figsize=(13, 7))\n",
        "\tplt.suptitle(\"3-D plot for resampled data using dimesnionality reduction (Biomedical Recurrence)\\n\\n\")\n",
        "\tax = fig.add_subplot(111, projection='3d')\n",
        "\tax.set_title(\"PCA\\n\\n\")\n",
        "\tax.view_init(elev=177,azim=-96)\n",
        "\tfor i in range(len(balanced_data[0][1])):\n",
        "\t\tif balanced_data[0][1][i] == 0:\n",
        "\t\t\tfalse = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='y', label=balanced_data[0][1][i])\n",
        "\t\telif balanced_data[0][1][i] == 1:\n",
        "\t\t\ttrue = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='g', label=balanced_data[0][1][i])\n",
        "\tplt.legend((false, true),\n",
        "\t\t(\"Didn't recur\", \"Recurred\"),\n",
        "\t\tscatterpoints=1,\n",
        "\t\tloc='upper right',\n",
        "\t\tncol=1,\n",
        "\t\tfontsize=10)\n",
        "\t#plt.show()\n",
        "\treturn results\n",
        "\n",
        "\n",
        "def main():\n",
        "\tprint('This file contains only callable functions. Run \"final_compiled.py\" instead.')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TabError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-c854985a4faf>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    print(t_columns)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "guEb_RH16IAf",
        "outputId": "82afcfa9-44e4-4097-bc00-99f5c44ae2aa"
      },
      "source": [
        "'''\n",
        "Predicting Features from the Pathology Report for Prostate Cancer.\n",
        "\n",
        "Gleason Score\n",
        "T-Stage\n",
        "Biomedical Recurrence\n",
        "'''\n",
        "\n",
        "# import statements\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import decomposition\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.ensemble import IsolationForest\n",
        "#from feature_processing import do_t_stage, do_gleason, do_t_recur\n",
        "\n",
        "\n",
        "# set module variables \n",
        "pd.set_option(\"expand_frame_repr\", False)\n",
        "pd.set_option(\"max_columns\", 9)\n",
        "np.random.seed(0)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "modes = ['show', 'partial', 'hide']\n",
        "mode = modes[1]\n",
        "\n",
        "# filepaths to data downloaded from cBioPortal\n",
        "filepath = \"prad_tcga\"\t\t\t# base directory\n",
        "#filenames = [\"data_methylation_hm450.txt\", \"data_RNA_Seq_v2_expression_median.txt\"]\n",
        "filenames=[\"TCGA-FPKM-DEG.xlsx\"]\n",
        "clinicalfile = \"prad_tcga_clinical_data.tsv\"\n",
        "\n",
        "# import the gene data (contains gene data to use as x-features while predicting)\n",
        "data = []\n",
        "for i, filename in enumerate(filenames):\n",
        "    TCGA_PRAD = pd.read_excel(\"TCGA-FPKM-DEG.xlsx\", header =None)\n",
        "    TCGA_PRAD = TCGA_PRAD.T\n",
        "    a = TCGA_PRAD\n",
        "    a = a.T\n",
        "    header_1 = a.iloc[0]\n",
        "    a = a[1:]\n",
        "    a.columns = header_1\n",
        "    a = a.reset_index()\n",
        "    TCGA_processed = a\n",
        "\n",
        "    TCGA_processed = TCGA_processed.rename(columns={np.nan: 'samples'})\n",
        "        # data is tab separated\n",
        "    data.append(TCGA_processed)\n",
        "    #data.append(pd.read_csv(os.path.join(filepath, filenames[i]), sep=\"\\t\"))\n",
        "    # drop data columns that will not be used and change the index of the DataFrame\n",
        "    #data[i].drop('Entrez_Gene_Id', axis=1, inplace=True)\n",
        "    #data[i].set_index('Hugo_Symbol', inplace=True)\n",
        "    if mode == 'show':\n",
        "        print('FILENAME: {0} -\\n'.format(filenames[i]), data[i].head())\n",
        "# import the clinical data (contains target features to predict)\n",
        "#clinical_data = pd.read_csv(os.path.join(filepath, clinicalfile), sep=\"\\t\")\n",
        "#clinical_data.set_index('Sample ID', inplace=True)\n",
        "#if mode == 'show':\n",
        "#\tprint('FILENAME: clinical_data -\\n', clinical_data.head())\n",
        "\n",
        "# Transpose the gene data and add the target features to it\n",
        "t_data = []\n",
        "for i, d in enumerate(data):\n",
        "    t_data.append(d.fillna(d.mean()))\n",
        "    #missing = clinical_data.index.difference(d.transpose().index).tolist()\n",
        "\n",
        "print(t_data)\n",
        "# change TStage and Recurrence to integer values\n",
        "for i, d in enumerate(t_data):\n",
        "    t_data[i] = t_data[i][pd.notnull(t_data[i]['group'])]\n",
        "    enc = LabelEncoder()\n",
        "    # fit encoder to TStage \n",
        "    enc.fit(t_data[i]['group'].tolist())\n",
        "    t_data[i]['group'] = enc.transform(t_data[i]['group'].tolist())\n",
        "    tstage_mapping = dict(zip(enc.transform(enc.classes_), enc.classes_))\n",
        "    # fit encoder to Recurrence\n",
        "\n",
        "print(\"\\t\\tRisk-Level\")\n",
        "\n",
        "kbest = SelectKBest(score_func=chi2, k=350)\n",
        "scaler = StandardScaler()\n",
        "fs_data = []\n",
        "for i, d in enumerate(t_data):\n",
        "    print(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "    t_rows = list(d.index)\n",
        "    t_columns = d.columns[3:]\n",
        "    print(t_columns)\n",
        "    # K-best\n",
        "    print(d)\n",
        "\n",
        "    selector = kbest.fit(d.iloc[:, 3:], d.iloc[:, 2])\n",
        "    t_columns = t_columns[selector.get_support()]\n",
        "    fs_data.append(pd.DataFrame(selector.transform(t_data[i].iloc[:, 3:]), columns = t_columns, index=t_rows))\n",
        "    if mode == 'show':\n",
        "        print(\"Selecting k best features -\\n\", fs_data[i].head())\n",
        "    # Scale \n",
        "    t_columns = fs_data[i].columns\n",
        "    fs_data[i] = pd.DataFrame(scaler.fit_transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "    if mode == 'show':\n",
        "        print(\"Scaling data -\\n\", fs_data[i].head())\n",
        "    # Select from RF\n",
        "    classifier = RandomForestClassifier(n_estimators=1)\n",
        "    classifier = classifier.fit(fs_data[i], d['group'])\n",
        "    selector = SelectFromModel(classifier, prefit=True)\n",
        "    t_columns = t_columns[selector.get_support()]\n",
        "    fs_data[i] = pd.DataFrame(selector.transform(fs_data[i]), columns=t_columns, index=t_rows)\n",
        "    fs_data[i]['group'] = d['group']\n",
        "    if mode == 'show':\n",
        "        print(\"Selecting data from RF model -\\n\", fs_data[i].head())\n",
        "    print(\"Shape after feature selection: {}\".format(fs_data[i].shape), end=\"\\n\\n\")\n",
        "# RESAMPLING the data - SMOTEENN\n",
        "balanced_data = [[] for _ in range(2)]\n",
        "for i, d in enumerate(fs_data):\n",
        "    sme = SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=3))\n",
        "    x, y = sme.fit_resample(fs_data[i], t_data[i]['group'])\n",
        "    # x are the features and y are the targets\n",
        "    balanced_data[i].append(x)\n",
        "    balanced_data[i].append(y)\n",
        "    if mode == 'show':\n",
        "        print(\"FILENAME: {}\".format(filenames[i]), Counter(balanced_data[i][1]))\n",
        "# DIMENSIONALITY REDUCTION\n",
        "# Kernel PCA and LDA (can be toggled on or off)\n",
        "pca = True\n",
        "pca_dim = 31\n",
        "lda = True\n",
        "lda_dim = 5\n",
        "if pca or lda:\n",
        "    dr_data = []\n",
        "    for i in range(len(filenames)):\n",
        "        print(\"\\nFILENAME: {}\".format(filenames[i]))\n",
        "        if pca:\n",
        "            decomposer = KernelPCA(n_components=pca_dim, kernel='rbf', gamma=0.05, degree=7)\n",
        "            dr_data.append(decomposer.fit_transform(balanced_data[i][0]))\n",
        "            print(\"Shape and type after PCA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "        if lda:\n",
        "            decomposer = LinearDiscriminantAnalysis(n_components=lda_dim, solver='eigen')\n",
        "            dr_data[i] = decomposer.fit_transform(dr_data[i], balanced_data[i][1])\n",
        "            print(\"Shape and type after LDA: \", dr_data[i].shape, type(dr_data[i]))\n",
        "else:\n",
        "    dr_data.append(balanced_data[0][0])\n",
        "    dr_data.append(balanced_data[1][0])\n",
        "# CLASSIFICATION\n",
        "splits = 7\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
        "results = {'SVM': [],\n",
        "            'RF': [],\n",
        "            'KNN': [],\n",
        "            'NB': []\n",
        "            }\n",
        "for i, d in enumerate(dr_data):\n",
        "    # SVM\n",
        "    res = []\n",
        "    classifier = SVC(gamma='auto')\n",
        "    results['SVM'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "    results['SVM'][i] = results['SVM'][i].mean()\n",
        "    # RF\n",
        "    classifier = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=7, criterion='gini')\n",
        "    results['RF'].append(cross_val_score(classifier, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "    results['RF'][i] = results['RF'][i].mean()\n",
        "    # KNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    results['KNN'].append(cross_val_score(knn, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "    results['KNN'][i] = results['KNN'][i].mean()\n",
        "    # NB\n",
        "    nb = GaussianNB()\n",
        "    results['NB'].append(cross_val_score(nb, pd.DataFrame(dr_data[i]), balanced_data[i][1], cv=kfold))\n",
        "    results['NB'][i] = results['NB'][i].mean()\n",
        "print(\"\\nFinal Results for datasets: {0} -\".format(filenames[0]))\n",
        "pprint(results)\n",
        "# PLOTTING\n",
        "# PCA\n",
        "pca = PCA(n_components = 3)\n",
        "x_pca = pca.fit_transform(balanced_data[0][0])\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "plt.suptitle(\"3-D plot for resampled data using dimesnionality reduction (group)\\n\\n\")\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "ax.set_title(\"PCA\\n\\n\")\n",
        "ax.view_init(elev=15,azim=66)\n",
        "for i in range(len(balanced_data[0][1])):\n",
        "    if balanced_data[0][1][i] == 0:\n",
        "        t2a = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='y', label=balanced_data[0][1][i])\n",
        "    elif balanced_data[0][1][i] == 1:\n",
        "        t2b = ax.scatter(x_pca[i][0], x_pca[i][1], x_pca[i][2], c='g', label=balanced_data[0][1][i])\n",
        "plt.legend((t2a, t2b),\n",
        "    ('0', '1'),\n",
        "    scatterpoints=1,\n",
        "    loc='upper right',\n",
        "    ncol=1,\n",
        "    fontsize=10)\n",
        "# PCA + LDA\n",
        "pca = PCA(n_components = 10)\n",
        "x_pca = pca.fit_transform(balanced_data[0][0])\n",
        "lda = LinearDiscriminantAnalysis(n_components = 3)\n",
        "x_lda = lda.fit_transform(x_pca, balanced_data[0][1])\n",
        "#print(x_lda)\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "plt.title(\"PCA & LDA\\n\\n\")\n",
        "ax.view_init(elev=-79,azim=-7)\n",
        "# for i in range(len(balanced_data[0][1])):\n",
        "#     if balanced_data[0][1][i] == 0:\n",
        "#         t2a = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='y', label=balanced_data[0][1][i])\n",
        "#     elif balanced_data[0][1][i] == 1:\n",
        "#         t2b = ax.scatter(x_lda[i][0], x_lda[i][1], x_lda[i][2], c='g', label=balanced_data[0][1][i])\n",
        "# plt.legend((t2a, t2b),\n",
        "#             ('0', '1'),\n",
        "#             scatterpoints=1,\n",
        "#             loc='upper right',\n",
        "#             ncol=1,\n",
        "#             fontsize=10)\n",
        "\n",
        "# Plot the final results\n",
        "# DNA is the methylation hm450 file\n",
        "dna_res = {'SVM': [],\n",
        "        'RF': [],\n",
        "        'NB': [],\n",
        "        'KNN': []\n",
        "    }\n",
        "# RNA is the rna sequencing file\n",
        "rna_res = {'SVM': [],\n",
        "        'RF': [],\n",
        "        'NB': [],\n",
        "        'KNN': []\n",
        "    }\n",
        "r_results=r_risk_results=results\n",
        "for i in dna_res.keys():\n",
        "    dna_res[i].append(r_results[i][0])\n",
        "\n",
        "fig = plt.figure(figsize=(13, 7))\n",
        "fig.suptitle(\"Final Results\")\n",
        "# DNA FILE\n",
        "ax = fig.add_subplot(121)\n",
        "N = len(dna_res['SVM'])\n",
        "ind = np.arange(N)\n",
        "w = 0.11\n",
        "svm = ax.bar(ind, dna_res['SVM'], w, bottom=0, alpha=0.8, color='g')\n",
        "rf = ax.bar(ind+w, dna_res['RF'], w, bottom=0, alpha=0.8, color='r')\n",
        "nb = ax.bar(ind+2*w, dna_res['NB'], w, bottom=0, alpha=0.8, color='b')\n",
        "knn = ax.bar(ind+3*w, dna_res['KNN'], w, bottom=0, alpha=0.8, color='y')\n",
        "ax.set_title(\"Results using the classifiers for different target features on DNA File\")\n",
        "ax.set_xticks(ind+3*w/2)\n",
        "ax.set_xticklabels(('Risk'))\n",
        "ax.legend((svm[0], rf[0], nb[0], knn[0]), ('SVM', 'RF', 'NB', 'KNN'), loc='lower right')\n",
        "ax.yaxis.set_units('Percentages (%)')\n",
        "# RNA FILE\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0    index           Samples  group  ENSG00000004468  ...  ENSG00000280725  ENSG00000280800  ENSG00000281131  ENSG00000281566\n",
            "0        1  TCGA-VN-A88K-01A      1         0.054718  ...         0.000000              0.0         3.244470         0.000000\n",
            "1        2  TCGA-ZG-A9ND-01A      1         1.226355  ...         0.121655              0.0         0.022344         0.000000\n",
            "2        3  TCGA-EJ-A65F-01A      1         0.143490  ...         0.019424              0.0         8.918967         0.000000\n",
            "3        4  TCGA-ZG-A9L1-01A      1         4.120039  ...         0.030949              0.0         2.091828         0.000000\n",
            "4        5  TCGA-YL-A8HL-01A      1         9.151929  ...         0.000000              0.0       106.665524         0.000000\n",
            "..     ...               ...    ...              ...  ...              ...              ...              ...              ...\n",
            "407    408  TCGA-XK-AAK1-01A      0        13.889672  ...         0.000000              0.0         0.055930         0.000000\n",
            "408    409  TCGA-Y6-A8TL-01A      0        24.050263  ...         0.000000              0.0         0.018781         0.000000\n",
            "409    410  TCGA-YL-A8HO-01A      0         1.932398  ...         0.000000              0.0         0.035824         0.176416\n",
            "410    411  TCGA-YL-A8SH-01B      0         4.519472  ...         0.000000              0.0         0.080925         0.000000\n",
            "411    412  TCGA-ZG-A8QX-01A      0        16.715040  ...         0.000000              0.0         0.000000         0.024509\n",
            "\n",
            "[412 rows x 752 columns]]\n",
            "\t\tRisk-Level\n",
            "\n",
            "FILENAME: TCGA-FPKM-DEG.xlsx\n",
            "Index(['ENSG00000004468', 'ENSG00000008300', 'ENSG00000010282',\n",
            "       'ENSG00000015413', 'ENSG00000016490', 'ENSG00000021826',\n",
            "       'ENSG00000029559', 'ENSG00000042832', 'ENSG00000051341',\n",
            "       'ENSG00000060718',\n",
            "       ...\n",
            "       'ENSG00000279960', 'ENSG00000280089', 'ENSG00000280274',\n",
            "       'ENSG00000280411', 'ENSG00000280440', 'ENSG00000280719',\n",
            "       'ENSG00000280725', 'ENSG00000280800', 'ENSG00000281131',\n",
            "       'ENSG00000281566'],\n",
            "      dtype='object', name=0, length=749)\n",
            "0    index           Samples  group  ENSG00000004468  ...  ENSG00000280725  ENSG00000280800  ENSG00000281131  ENSG00000281566\n",
            "0        1  TCGA-VN-A88K-01A      1         0.054718  ...         0.000000              0.0         3.244470         0.000000\n",
            "1        2  TCGA-ZG-A9ND-01A      1         1.226355  ...         0.121655              0.0         0.022344         0.000000\n",
            "2        3  TCGA-EJ-A65F-01A      1         0.143490  ...         0.019424              0.0         8.918967         0.000000\n",
            "3        4  TCGA-ZG-A9L1-01A      1         4.120039  ...         0.030949              0.0         2.091828         0.000000\n",
            "4        5  TCGA-YL-A8HL-01A      1         9.151929  ...         0.000000              0.0       106.665524         0.000000\n",
            "..     ...               ...    ...              ...  ...              ...              ...              ...              ...\n",
            "407    408  TCGA-XK-AAK1-01A      0        13.889672  ...         0.000000              0.0         0.055930         0.000000\n",
            "408    409  TCGA-Y6-A8TL-01A      0        24.050263  ...         0.000000              0.0         0.018781         0.000000\n",
            "409    410  TCGA-YL-A8HO-01A      0         1.932398  ...         0.000000              0.0         0.035824         0.176416\n",
            "410    411  TCGA-YL-A8SH-01B      0         4.519472  ...         0.000000              0.0         0.080925         0.000000\n",
            "411    412  TCGA-ZG-A8QX-01A      0        16.715040  ...         0.000000              0.0         0.000000         0.024509\n",
            "\n",
            "[412 rows x 752 columns]\n",
            "Shape after feature selection: (412, 39)\n",
            "\n",
            "\n",
            "FILENAME: TCGA-FPKM-DEG.xlsx\n",
            "Shape and type after PCA:  (283, 31) <class 'numpy.ndarray'>\n",
            "Shape and type after LDA:  (283, 1) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-e3975f5547d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdr_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# RF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recall_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDRs5T3vs7oC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x7DHCRNs8Nr",
        "outputId": "f593a4e1-f31c-459a-c71c-3fc998c57a58"
      },
      "source": [
        "'''\n",
        "Predicting Features from the Pathology Report for Prostate Cancer.\n",
        "\n",
        "Gleason Score\n",
        "T-Stage\n",
        "Biomedical Recurrence\n",
        "'''\n",
        "\n",
        "# import statements\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import decomposition\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.ensemble import IsolationForest\n",
        "#from feature_processing import do_t_stage, do_gleason, do_t_recur\n",
        "\n",
        "\n",
        "# set module variables \n",
        "pd.set_option(\"expand_frame_repr\", False)\n",
        "pd.set_option(\"max_columns\", 9)\n",
        "np.random.seed(0)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "modes = ['show', 'partial', 'hide']\n",
        "mode = modes[1]\n",
        "\n",
        "# filepaths to data downloaded from cBioPortal\n",
        "filepath = \"prad_tcga\"\t\t\t# base directory\n",
        "filenames = [\"data_methylation_hm450.txt\", \"data_RNA_Seq_v2_expression_median.txt\"]\n",
        "clinicalfile = \"prad_tcga_clinical_data.tsv\"\n",
        "\n",
        "# import the gene data (contains gene data to use as x-features while predicting)\n",
        "data = []\n",
        "TCGA_PRAD = pd.read_excel(\"TCGA-FPKM-DEG.xlsx\", header =None)\n",
        "print(TCGA_PRAD)\n",
        "\n",
        "for i, filename in enumerate(filenames):\n",
        "    # data is tab separated\n",
        "    data.append(pd.read_csv( filenames[i], sep=\"\\t\"))\n",
        "    # drop data columns that will not be used and change the index of the DataFrame\n",
        "    #print(data[i])\n",
        "    data[i].drop('Entrez_Gene_Id', axis=1, inplace=True)\n",
        "    data[i].set_index('Hugo_Symbol', inplace=True)\n",
        "    #print(data[i])\n",
        "    #print('FILENAME: RNA -\\n', data.head)\n",
        "\t# Transpose the gene data and add the target features to it\n",
        "t_data = []\n",
        "for i, d in enumerate(data):\n",
        "    t_data.append(d.fillna(d.mean()).transpose())\n",
        "    missing = clinical_data.index.difference(d.transpose().index).tolist()\n",
        "    t_data[i]['TStage'] = clinical_data.drop(missing)['American Joint Committee on Cancer Tumor Stage Code']\n",
        "    t_data[i]['Gleason'] = clinical_data.drop(missing)['Radical Prostatectomy Gleason Score for Prostate Cancer']\n",
        "    t_data[i]['Recurrence'] = clinical_data.drop(missing)['Biochemical Recurrence Indicator']\n",
        "    if mode == 'show':\n",
        "        print(\"\\n\\t\\tSkip the missing patient records and append the target values for all the others.\\n\", \"FILENAME: {}\".format(filenames[i]))\n",
        "        print(t_data[i].head())\n",
        "    print(t_data[i])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  0      1                2                3    ...              747              748              749              750\n",
            "0             Samples  group  ENSG00000004468  ENSG00000008300  ...  ENSG00000280725  ENSG00000280800  ENSG00000281131  ENSG00000281566\n",
            "1    TCGA-VN-A88K-01A      1        0.0547183         0.212032  ...                0                0          3.24447                0\n",
            "2    TCGA-ZG-A9ND-01A      1          1.22635         0.335367  ...         0.121655                0        0.0223444                0\n",
            "3    TCGA-EJ-A65F-01A      1          0.14349         0.351557  ...        0.0194239                0          8.91897                0\n",
            "4    TCGA-ZG-A9L1-01A      1          4.12004        0.0353032  ...        0.0309485                0          2.09183                0\n",
            "..                ...    ...              ...              ...  ...              ...              ...              ...              ...\n",
            "408  TCGA-XK-AAK1-01A      0          13.8897          0.17368  ...                0                0        0.0559298                0\n",
            "409  TCGA-Y6-A8TL-01A      0          24.0503         0.157466  ...                0                0         0.018781                0\n",
            "410  TCGA-YL-A8HO-01A      0           1.9324        0.0945576  ...                0                0        0.0358238         0.176416\n",
            "411  TCGA-YL-A8SH-01B      0          4.51947         0.958276  ...                0                0        0.0809246                0\n",
            "412  TCGA-ZG-A8QX-01A      0           16.715         0.211216  ...                0                0                0         0.024509\n",
            "\n",
            "[413 rows x 751 columns]\n",
            "Hugo_Symbol        TSEN34  ATP6V1G2      CKLF     SFRS7  ...     PTAR1  TStage  Gleason  Recurrence\n",
            "TCGA-2A-A8VL-01  0.079530  0.051522  0.072209  0.056550  ...  0.071303     T2b        6          NO\n",
            "TCGA-2A-A8VO-01  0.089634  0.056122  0.071083  0.047975  ...  0.042870     T3a        6          NO\n",
            "TCGA-2A-A8VT-01  0.076990  0.050440  0.051748  0.048460  ...  0.041263      T4        9          NO\n",
            "TCGA-2A-A8VV-01  0.090520  0.059499  0.062675  0.062554  ...  0.091165     T2b        6          NO\n",
            "TCGA-2A-A8VX-01  0.077796  0.050275  0.087197  0.067649  ...  0.038419     T3b        8          NO\n",
            "...                   ...       ...       ...       ...  ...       ...     ...      ...         ...\n",
            "TCGA-ZG-A9M4-01  0.094714  0.114515  0.068698  0.033360  ...  0.108428     T3b        9          NO\n",
            "TCGA-ZG-A9MC-01  0.120451  0.059743  0.044572  0.055329  ...  0.084421     T3b        9          NO\n",
            "TCGA-ZG-A9N3-01  0.096987  0.048492  0.047550  0.046055  ...  0.049582     T3b        9          NO\n",
            "TCGA-ZG-A9ND-01  0.068457  0.042226  0.049961  0.044231  ...  0.047747     T3a        9          NO\n",
            "TCGA-ZG-A9NI-01  0.086210  0.083151  0.063409  0.042646  ...  0.071440     T3b        9          NO\n",
            "\n",
            "[499 rows x 16484 columns]\n",
            "Hugo_Symbol      LOC100130426  UBE2Q2P3  UBE2Q2P3   HMGB1P1  ...  AKR1C6P  TStage  Gleason  Recurrence\n",
            "TCGA-2A-A8VL-01        0.0000   20.7518   17.3532   80.9114  ...   0.0000     T2b        6          NO\n",
            "TCGA-2A-A8VO-01        0.0000   19.3206   13.9105   62.0757  ...   0.0000     T3a        6          NO\n",
            "TCGA-2A-A8VT-01        0.0000   48.8860   59.2022   94.4228  ...   0.3676      T4        9          NO\n",
            "TCGA-2A-A8VV-01        0.0000   21.7343   16.3878  108.1492  ...   0.0000     T2b        6          NO\n",
            "TCGA-2A-A8VX-01        0.0000    2.9525    8.6358   96.9240  ...   0.0000     T3b        8          NO\n",
            "...                       ...       ...       ...       ...  ...      ...     ...      ...         ...\n",
            "TCGA-ZG-A9M4-01        0.4443   19.4917   26.6425  124.4212  ...   0.0000     T3b        9          NO\n",
            "TCGA-ZG-A9MC-01        0.0000   13.1381   14.8899  105.5155  ...   0.0000     T3b        9          NO\n",
            "TCGA-ZG-A9N3-01        0.0000    6.4103    6.9445  126.9525  ...   0.0000     T3b        9          NO\n",
            "TCGA-ZG-A9ND-01        0.0000   10.4997   23.3927   64.4925  ...   0.0000     T3a        9          NO\n",
            "TCGA-ZG-A9NI-01        0.0000   13.9401    7.1016   79.0267  ...   0.0000     T3b        9          NO\n",
            "\n",
            "[498 rows x 20534 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}